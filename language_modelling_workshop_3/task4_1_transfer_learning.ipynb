{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pitLHPAipQQm"
   },
   "source": [
    "## Transfer learning\n",
    "\n",
    "2018 showed us that language modelling is a good task to train powerfull text representations. There are two different approaches how to use this representations: **feature extraction** and **fine-tuning**.\n",
    "\n",
    "  * One great example of feature extraction is ELMo ([allennlp tutorial](https://github.com/allenai/allennlp/blob/master/tutorials/how_to/elmo.md), [tf_hub example](https://tfhub.dev/google/elmo/2), [deeppavlov documentation](http://docs.deeppavlov.ai/en/master/apiref/models/embedders.html?highlight=elmo#deeppavlov.models.embedders.elmo_embedder.ELMoEmbedder))\n",
    "  * One great example of fine-tuning is ULMfit - ([fastai lesson](https://course.fast.ai/videos/?lesson=4), [example notebook](https://nbviewer.jupyter.org/github/fastai/course-v3/blob/master/nbs/dl1/lesson3-imdb.ipynb))\n",
    "\n",
    "What should you do?\n",
    "\n",
    "  * Apply ELMo to make named entity recognition system. You can use [CONLL 2003 dataset (en)](http://files.deeppavlov.ai/deeppavlov_data/conll2003_v2.tar.gz) or [Persons1000 dataset (ru)](http://labinform.ru/pub/named_entities/descr_ne.htm) or any other dataset.\n",
    "  * Apply ULMfit to make text classificator (any dataset, except IMDB)\n",
    "  * Apply ELMo to make text classificator (on the same dataset)\n",
    "  * Play with various models and hyperparameters\n",
    "  * Compare results\n",
    "\n",
    "\n",
    "**Results of this task:**\n",
    "  * NER model\n",
    "  * Two classification models\n",
    "  * for each model:\n",
    "    * metrics on the test set (quantitative evaluation)\n",
    "    * succesfull and _unsucsessfull_ examples (qualitative evaluation)\n",
    "    * plots showing that the model is training\n",
    "\n",
    "\n",
    "**Additional points:**\n",
    "  * Early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2936
    },
    "colab_type": "code",
    "id": "gaiio4Bgf7mb",
    "outputId": "7e8b67b6-8baf-41ee-f6db-c80b2af3a0de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting allennlp\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/c8/10342a6068a8d156a5947e03c95525d559e71ad62de0f2585ab922e14533/allennlp-0.8.3-py3-none-any.whl (5.6MB)\n",
      "\u001b[K    100% |████████████████████████████████| 5.6MB 6.3MB/s \n",
      "\u001b[?25hCollecting pytorch-pretrained-bert>=0.6.0 (from allennlp)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/3c/d5fa084dd3a82ffc645aba78c417e6072ff48552e3301b1fa3bd711e03d4/pytorch_pretrained_bert-0.6.1-py3-none-any.whl (114kB)\n",
      "\u001b[K    100% |████████████████████████████████| 122kB 39.3MB/s \n",
      "\u001b[?25hCollecting parsimonious>=0.8.0 (from allennlp)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/fc/067a3f89869a41009e1a7cdfb14725f8ddd246f30f63c645e8ef8a1c56f4/parsimonious-0.8.1.tar.gz (45kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 24.7MB/s \n",
      "\u001b[?25hCollecting unidecode (from allennlp)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/31/39/53096f9217b057cb049fe872b7fc7ce799a1a89b76cf917d9639e7a558b5/Unidecode-1.0.23-py2.py3-none-any.whl (237kB)\n",
      "\u001b[K    100% |████████████████████████████████| 245kB 29.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: spacy<2.2,>=2.0 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.0.18)\n",
      "Collecting tensorboardX>=1.2 (from allennlp)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/76/89dd44458eb976347e5a6e75eb79fecf8facd46c1ce259bad54e0044ea35/tensorboardX-1.6-py2.py3-none-any.whl (129kB)\n",
      "\u001b[K    100% |████████████████████████████████| 133kB 34.0MB/s \n",
      "\u001b[?25hCollecting flask-cors>=3.0.7 (from allennlp)\n",
      "  Downloading https://files.pythonhosted.org/packages/65/cb/683f71ff8daa3aea0a5cbb276074de39f9ab66d3fbb8ad5efb5bb83e90d2/Flask_Cors-3.0.7-py2.py3-none-any.whl\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.2.5)\n",
      "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.0.1.post2)\n",
      "Requirement already satisfied: sqlparse>=0.2.4 in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.3.0)\n",
      "Collecting flaky (from allennlp)\n",
      "  Downloading https://files.pythonhosted.org/packages/02/42/cca66659a786567c8af98587d66d75e7d2b6e65662f8daab75db708ac35b/flaky-3.5.3-py2.py3-none-any.whl\n",
      "Collecting jsonnet>=0.10.0; sys_platform != \"win32\" (from allennlp)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/dc/3abd3971869a741d7acdba166d71d4f9366b6b53028dfd56f95de356af0f/jsonnet-0.12.1.tar.gz (240kB)\n",
      "\u001b[K    100% |████████████████████████████████| 245kB 33.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.8.0)\n",
      "Collecting word2number>=1.1 (from allennlp)\n",
      "  Downloading https://files.pythonhosted.org/packages/4a/29/a31940c848521f0725f0df6b25dca8917f13a2025b0e8fcbe5d0457e45e6/word2number-1.1.zip\n",
      "Requirement already satisfied: editdistance in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.5.3)\n",
      "Requirement already satisfied: flask>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.0.2)\n",
      "Collecting conllu==0.11 (from allennlp)\n",
      "  Downloading https://files.pythonhosted.org/packages/d4/2c/856344d9b69baf5b374c395b4286626181a80f0c2b2f704914d18a1cea47/conllu-0.11-py2.py3-none-any.whl\n",
      "Requirement already satisfied: msgpack<0.6.0,>=0.5.6 in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.5.6)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.20.3)\n",
      "Requirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.6/dist-packages (from allennlp) (4.28.1)\n",
      "Collecting moto>=1.3.4 (from allennlp)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/57/40/cec89fa5c13108eb1c8de435633f8b7639e0e43fcbcdc8ac52633efeeabe/moto-1.3.7-py2.py3-none-any.whl (552kB)\n",
      "\u001b[K    100% |████████████████████████████████| 552kB 27.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: gevent>=1.3.6 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.4.0)\n",
      "Collecting awscli>=1.11.91 (from allennlp)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/41/f03fa1b10c7619262da75d34ce93067c9f0dc274dbd482200250319d9bef/awscli-1.16.140-py2.py3-none-any.whl (1.5MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.5MB 16.2MB/s \n",
      "\u001b[?25hCollecting responses>=0.7 (from allennlp)\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/5a/b887e89925f1de7890ef298a74438371ed4ed29b33def9e6d02dc6036fd8/responses-0.10.6-py2.py3-none-any.whl\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.9.130)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.16.2)\n",
      "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.0.3)\n",
      "Collecting ftfy (from allennlp)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/86/df789c5834f15ae1ca53a8d4c1fc4788676c2e32112f6a786f2625d9c6e6/ftfy-5.5.1-py3-none-any.whl (43kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 23.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2018.9)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.2.1)\n",
      "Collecting overrides (from allennlp)\n",
      "  Downloading https://files.pythonhosted.org/packages/de/55/3100c6d14c1ed177492fcf8f07c4a7d2d6c996c0a7fc6a9a0a41308e7eec/overrides-1.9.tar.gz\n",
      "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.6.4)\n",
      "Requirement already satisfied: requests>=2.18 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.18.4)\n",
      "Collecting numpydoc>=0.8.0 (from allennlp)\n",
      "  Downloading https://files.pythonhosted.org/packages/95/a8/b4706a6270f0475541c5c1ee3373c7a3b793936ec1f517f1a1dab4f896c0/numpydoc-0.8.0.tar.gz\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert>=0.6.0->allennlp) (2018.1.10)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from parsimonious>=0.8.0->allennlp) (1.11.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.0->allennlp) (1.0.2)\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.0->allennlp) (0.9.6)\n",
      "Requirement already satisfied: dill<0.3,>=0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.0->allennlp) (0.2.9)\n",
      "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.0->allennlp) (2.0.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.0->allennlp) (2.0.2)\n",
      "Requirement already satisfied: thinc<6.13.0,>=6.12.1 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.0->allennlp) (6.12.1)\n",
      "Requirement already satisfied: ujson>=1.35 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.0->allennlp) (1.35)\n",
      "Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX>=1.2->allennlp) (3.7.1)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->allennlp) (1.1.0)\n",
      "Requirement already satisfied: Werkzeug>=0.14 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->allennlp) (0.15.2)\n",
      "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->allennlp) (7.0)\n",
      "Requirement already satisfied: Jinja2>=2.10 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->allennlp) (2.10.1)\n",
      "Requirement already satisfied: boto>=2.36.0 in /usr/local/lib/python3.6/dist-packages (from moto>=1.3.4->allennlp) (2.49.0)\n",
      "Collecting python-jose<3.0.0 (from moto>=1.3.4->allennlp)\n",
      "  Downloading https://files.pythonhosted.org/packages/bf/5c/5fa238c0c5b0656994b52721dd8b1d7bf52ebd8786518dde794f44de86b6/python_jose-2.0.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from moto>=1.3.4->allennlp) (2.5.3)\n",
      "Collecting pyaml (from moto>=1.3.4->allennlp)\n",
      "  Downloading https://files.pythonhosted.org/packages/c5/e1/1523fb1dab744e2c6b1f02446f2139a78726c18c062a8ddd53875abb20f8/pyaml-18.11.0-py2.py3-none-any.whl\n",
      "Collecting xmltodict (from moto>=1.3.4->allennlp)\n",
      "  Downloading https://files.pythonhosted.org/packages/28/fd/30d5c1d3ac29ce229f6bdc40bbc20b28f716e8b363140c26eff19122d8a5/xmltodict-0.12.0-py2.py3-none-any.whl\n",
      "Collecting aws-xray-sdk<0.96,>=0.93 (from moto>=1.3.4->allennlp)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/a5/da7887285564f9e0ae5cd25a453cca36e2cd43d8ccc9effde260b4d80904/aws_xray_sdk-0.95-py2.py3-none-any.whl (52kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 21.4MB/s \n",
      "\u001b[?25hCollecting jsondiff==1.1.1 (from moto>=1.3.4->allennlp)\n",
      "  Downloading https://files.pythonhosted.org/packages/bd/5f/13e28a2f9abeda2ffb3f44f2f809b01b52bc02cdb63816e05b8c9cbbdfc5/jsondiff-1.1.1.tar.gz\n",
      "Collecting cryptography>=2.3.0 (from moto>=1.3.4->allennlp)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5b/12/b0409a94dad366d98a8eee2a77678c7a73aafd8c0e4b835abea634ea3896/cryptography-2.6.1-cp34-abi3-manylinux1_x86_64.whl (2.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 2.3MB 15.3MB/s \n",
      "\u001b[?25hCollecting docker>=2.5.1 (from moto>=1.3.4->allennlp)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/68/c3afca1a5aa8d2997ec3b8ee822a4d752cf85907b321f07ea86888545152/docker-3.7.2-py2.py3-none-any.whl (134kB)\n",
      "\u001b[K    100% |████████████████████████████████| 143kB 28.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: botocore>=1.12.13 in /usr/local/lib/python3.6/dist-packages (from moto>=1.3.4->allennlp) (1.12.130)\n",
      "Requirement already satisfied: mock in /usr/local/lib/python3.6/dist-packages (from moto>=1.3.4->allennlp) (2.0.0)\n",
      "Requirement already satisfied: greenlet>=0.4.14; platform_python_implementation == \"CPython\" in /usr/local/lib/python3.6/dist-packages (from gevent>=1.3.6->allennlp) (0.4.15)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from awscli>=1.11.91->allennlp) (0.2.0)\n",
      "Collecting rsa<=3.5.0,>=3.1.2 (from awscli>=1.11.91->allennlp)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e1/ae/baedc9cb175552e95f3395c43055a6a5e125ae4d48a1d7a924baca83e92e/rsa-3.4.2-py2.py3-none-any.whl (46kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 27.1MB/s \n",
      "\u001b[?25hCollecting colorama<=0.3.9,>=0.2.5 (from awscli>=1.11.91->allennlp)\n",
      "  Downloading https://files.pythonhosted.org/packages/db/c8/7dcf9dbcb22429512708fe3a547f8b6101c0d02137acbd892505aee57adf/colorama-0.3.9-py2.py3-none-any.whl\n",
      "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from awscli>=1.11.91->allennlp) (0.14)\n",
      "Requirement already satisfied: PyYAML<=3.13,>=3.10 in /usr/local/lib/python3.6/dist-packages (from awscli>=1.11.91->allennlp) (3.13)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp) (0.9.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (1.0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (2.4.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy->allennlp) (0.1.7)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (7.0.0)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (1.3.0)\n",
      "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (0.7.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (40.9.0)\n",
      "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (1.8.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (19.1.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (2019.3.9)\n",
      "Requirement already satisfied: sphinx>=1.2.3 in /usr/local/lib/python3.6/dist-packages (from numpydoc>=0.8.0->allennlp) (1.8.5)\n",
      "Requirement already satisfied: msgpack-numpy<0.4.4 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy<2.2,>=2.0->allennlp) (0.4.3.2)\n",
      "Requirement already satisfied: wrapt<1.11.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy<2.2,>=2.0->allennlp) (1.10.11)\n",
      "Requirement already satisfied: cytoolz<0.10,>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy<2.2,>=2.0->allennlp) (0.9.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10->flask>=1.0.2->allennlp) (1.1.1)\n",
      "Collecting pycryptodome<4.0.0,>=3.3.1 (from python-jose<3.0.0->moto>=1.3.4->allennlp)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/06/fc/b09816d7b2d79d6454f75b40def94a89ed785d8d8d07840563f1084c6ecd/pycryptodome-3.8.1-cp36-cp36m-manylinux1_x86_64.whl (9.7MB)\n",
      "\u001b[K    100% |████████████████████████████████| 9.7MB 5.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: future<1.0 in /usr/local/lib/python3.6/dist-packages (from python-jose<3.0.0->moto>=1.3.4->allennlp) (0.16.0)\n",
      "Collecting ecdsa<1.0 (from python-jose<3.0.0->moto>=1.3.4->allennlp)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/f4/73669d51825516ce8c43b816c0a6b64cd6eb71d08b99820c00792cb42222/ecdsa-0.13-py2.py3-none-any.whl (86kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 35.5MB/s \n",
      "\u001b[?25hCollecting jsonpickle (from aws-xray-sdk<0.96,>=0.93->moto>=1.3.4->allennlp)\n",
      "  Downloading https://files.pythonhosted.org/packages/dc/12/8c44eabb501e2bc0aec0dd152b328074d98a50968d3a02be28f6037f0c6a/jsonpickle-1.1-py2.py3-none-any.whl\n",
      "Collecting asn1crypto>=0.21.0 (from cryptography>=2.3.0->moto>=1.3.4->allennlp)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/cd/35485615f45f30a510576f1a56d1e0a7ad7bd8ab5ed7cdc600ef7cd06222/asn1crypto-0.24.0-py2.py3-none-any.whl (101kB)\n",
      "\u001b[K    100% |████████████████████████████████| 102kB 38.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: cffi!=1.11.3,>=1.8 in /usr/local/lib/python3.6/dist-packages (from cryptography>=2.3.0->moto>=1.3.4->allennlp) (1.12.2)\n",
      "Collecting websocket-client>=0.32.0 (from docker>=2.5.1->moto>=1.3.4->allennlp)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/19/44753eab1fdb50770ac69605527e8859468f3c0fd7dc5a76dd9c4dbd7906/websocket_client-0.56.0-py2.py3-none-any.whl (200kB)\n",
      "\u001b[K    100% |████████████████████████████████| 204kB 40.1MB/s \n",
      "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from docker>=2.5.1->moto>=1.3.4->allennlp)\n",
      "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python3.6/dist-packages (from mock->moto>=1.3.4->allennlp) (5.1.3)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<=3.5.0,>=3.1.2->awscli>=1.11.91->allennlp) (0.4.5)\n",
      "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.2.3->numpydoc>=0.8.0->allennlp) (0.7.12)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.2.3->numpydoc>=0.8.0->allennlp) (19.0)\n",
      "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.2.3->numpydoc>=0.8.0->allennlp) (2.1.3)\n",
      "Requirement already satisfied: imagesize in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.2.3->numpydoc>=0.8.0->allennlp) (1.1.0)\n",
      "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.2.3->numpydoc>=0.8.0->allennlp) (1.1.0)\n",
      "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.2.3->numpydoc>=0.8.0->allennlp) (1.2.1)\n",
      "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.2.3->numpydoc>=0.8.0->allennlp) (2.6.0)\n",
      "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cytoolz<0.10,>=0.9.0->thinc<6.13.0,>=6.12.1->spacy<2.2,>=2.0->allennlp) (0.9.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.3.0->moto>=1.3.4->allennlp) (2.19)\n",
      "Building wheels for collected packages: parsimonious, jsonnet, word2number, overrides, numpydoc, jsondiff\n",
      "  Building wheel for parsimonious (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/b7/8d/e7/a0e74217da5caeb3c1c7689639b6d28ddbf9985b840bc96a9a\n",
      "  Building wheel for jsonnet (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/f0/47/51/a178b15274ed0db775a1ae9c799ce31e511609c3ab75a7dec5\n",
      "  Building wheel for word2number (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/46/2f/53/5f5c1d275492f2fce1cdab9a9bb12d49286dead829a4078e0e\n",
      "  Building wheel for overrides (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/8d/52/86/e5a83b1797e7d263b458d2334edd2704c78508b3eea9323718\n",
      "  Building wheel for numpydoc (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/ea/55/7f/3e25d754760ccd62d6796e5b2cfe25629346f52ea00753d549\n",
      "  Building wheel for jsondiff (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/68/08/07/69d839606fb7fdc778fa86476abc0a864693d45969a0c1936c\n",
      "Successfully built parsimonious jsonnet word2number overrides numpydoc jsondiff\n",
      "Installing collected packages: pytorch-pretrained-bert, parsimonious, unidecode, tensorboardX, flask-cors, flaky, jsonnet, word2number, conllu, pycryptodome, ecdsa, python-jose, pyaml, xmltodict, responses, jsonpickle, aws-xray-sdk, jsondiff, asn1crypto, cryptography, websocket-client, docker-pycreds, docker, moto, rsa, colorama, awscli, ftfy, overrides, numpydoc, allennlp\n",
      "  Found existing installation: rsa 4.0\n",
      "    Uninstalling rsa-4.0:\n",
      "      Successfully uninstalled rsa-4.0\n",
      "Successfully installed allennlp-0.8.3 asn1crypto-0.24.0 aws-xray-sdk-0.95 awscli-1.16.140 colorama-0.3.9 conllu-0.11 cryptography-2.6.1 docker-3.7.2 docker-pycreds-0.4.0 ecdsa-0.13 flaky-3.5.3 flask-cors-3.0.7 ftfy-5.5.1 jsondiff-1.1.1 jsonnet-0.12.1 jsonpickle-1.1 moto-1.3.7 numpydoc-0.8.0 overrides-1.9 parsimonious-0.8.1 pyaml-18.11.0 pycryptodome-3.8.1 python-jose-2.0.2 pytorch-pretrained-bert-0.6.1 responses-0.10.6 rsa-3.4.2 tensorboardX-1.6 unidecode-1.0.23 websocket-client-0.56.0 word2number-1.1 xmltodict-0.12.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "rsa"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install allennlp # for getting elmo embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uT6P4rM1pQQo"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as func\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "import torch.utils.data as utils\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import csv\n",
    "import pandas as pd\n",
    "import allennlp\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 32
    },
    "colab_type": "code",
    "id": "KYTn_fPjpQQu",
    "outputId": "e8028cba-587a-476e-94a7-e3d26ae68b89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_TOay_NtpQQ0"
   },
   "source": [
    "# NER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PYDDbBeBhSIF"
   },
   "source": [
    "*Online solver for cheaters*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 342
    },
    "colab_type": "code",
    "id": "1IsKh7mtJUAo",
    "outputId": "6a7b916f-4d7c-48fa-afb4-3d8da6c7e5ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 711306412/711306412 [00:10<00:00, 70296829.38B/s]\n",
      "/usr/local/lib/python3.6/dist-packages/allennlp/data/token_indexers/token_characters_indexer.py:51: UserWarning: You are using the default value (0) of `min_padding_length`, which can cause some subtle bugs (more info see https://github.com/allenai/allennlp/issues/1954). Strongly recommend to set a value, usually the maximum size of the convolutional layer size when using CnnEncoder.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logits': [[15.190458297729492, -4.716231822967529, 1.5143320560455322, -8.693986892700195, -5.3672637939453125, -1.8563754558563232, -3.214425802230835, -4.376181602478027, -6.056004524230957, -2.422358989715576, -4.920343399047852, -6.915403366088867, -2.8212313652038574, -4.298392295837402, -1.8804082870483398, -3.06772518157959, -4.711836338043213], [-1.3631693124771118, -2.0067806243896484, 4.746016025543213, 4.566849708557129, -0.578734815120697, 3.3536217212677, -3.244018316268921, -5.067802429199219, 16.73503875732422, -6.667780876159668, -3.404334783554077, -4.538154602050781, -3.13637113571167, -3.4001007080078125, -4.961193084716797, -6.998348236083984, -6.066359043121338], [12.128942489624023, -3.83430552482605, -6.2508344650268555, 1.3990728855133057, -6.805897235870361, -3.7989420890808105, -5.914254188537598, -1.5350010395050049, -3.1357712745666504, -1.1868269443511963, -7.6140336990356445, -0.8967913389205933, -3.826099157333374, -1.8193367719650269, -1.0901379585266113, -1.1614727973937988, -2.551198720932007], [13.074651718139648, -3.3860416412353516, -2.6409034729003906, -3.9366040229797363, -4.175083160400391, -4.548679351806641, -2.324118137359619, -2.1475770473480225, -2.3154046535491943, -0.7065699100494385, -5.419186115264893, -3.69488525390625, -2.9159762859344482, -3.0558290481567383, -1.3406548500061035, -3.5838942527770996, -2.731867551803589], [13.86935806274414, -4.056713581085205, -3.133209705352783, -4.064491271972656, -4.512843132019043, -4.958012580871582, -2.935107707977295, -1.9482825994491577, -2.92555832862854, -0.8700639605522156, -6.256455421447754, -3.6904757022857666, -3.290785551071167, -3.0265164375305176, -1.1682897806167603, -4.198452472686768, -2.7169642448425293], [13.238302230834961, -3.7431111335754395, -3.0792651176452637, -3.6680617332458496, -4.726833820343018, -4.4394989013671875, -3.2482995986938477, -1.5071406364440918, -3.2976880073547363, -0.654589056968689, -5.993527412414551, -2.9567184448242188, -3.2536561489105225, -2.583261251449585, -1.0597245693206787, -3.589456558227539, -2.215608835220337], [12.916813850402832, -3.638181686401367, -2.545154333114624, -4.825210094451904, -3.470892906188965, -3.6505417823791504, -2.4026622772216797, -1.4803152084350586, -3.506791114807129, -0.5663822293281555, -5.356991291046143, -3.577092170715332, -2.056088924407959, -2.2591772079467773, -0.7746957540512085, -3.0474443435668945, -2.569117546081543], [7.839572906494141, -3.2952303886413574, -0.39105165004730225, -9.112371444702148, -2.885373592376709, 0.0392535924911499, 3.7038044929504395, -6.64643669128418, -3.098616361618042, -1.4827512502670288, -1.3292959928512573, -8.539006233215332, 6.627438545227051, -6.656042098999023, 2.063732624053955, -4.451451301574707, -4.58940315246582], [2.592849016189575, -8.707053184509277, 1.2151813507080078, -2.8693125247955322, -3.4390816688537598, -0.6568314433097839, 1.7230433225631714, -2.2636067867279053, -1.4117341041564941, 2.376500129699707, -3.9921088218688965, -6.455913543701172, 5.6532368659973145, 0.017253398895263672, 9.436369895935059, -1.4654641151428223, -1.575580358505249], [7.149562835693359, -8.770298957824707, -0.8339781761169434, -2.7221922874450684, -7.668472766876221, -4.826708793640137, -3.538393497467041, -0.7372443675994873, -7.572826385498047, 3.8226914405822754, -6.001620292663574, -5.426424026489258, 1.317143440246582, 2.167490005493164, 10.891902923583984, -0.4214038848876953, -0.9163004159927368], [2.08204984664917, -4.678183078765869, -3.726269245147705, 4.6691484451293945, -4.017053127288818, 3.837398052215576, -6.871837139129639, 1.3259888887405396, 2.7708725929260254, -2.776038408279419, -6.526082992553711, -3.1035573482513428, -3.912303924560547, 8.290249824523926, 1.3892667293548584, -5.593270301818848, -5.472158432006836], [14.985151290893555, -4.0832953453063965, -5.03541374206543, -4.26874303817749, -6.470174789428711, -5.128262996673584, -5.393654823303223, -1.0995310544967651, -6.0809221267700195, -0.8405821919441223, -6.666752338409424, -2.4697978496551514, -4.361674785614014, -0.3781011402606964, -0.7164169549942017, -3.300325393676758, -3.4684205055236816], [12.440936088562012, -2.722841739654541, -2.467388391494751, -4.148253440856934, -3.92233943939209, -4.2056779861450195, -2.4409146308898926, -1.5162516832351685, -3.5684046745300293, -0.8063201904296875, -4.344292640686035, -2.8878400325775146, -3.0685465335845947, -2.0787124633789062, -1.3628685474395752, -2.829662799835205, -1.9396997690200806], [14.01376724243164, -4.0822529792785645, -3.0010218620300293, -4.704466342926025, -4.5541839599609375, -4.369335174560547, -3.0633468627929688, -1.4963881969451904, -4.620249271392822, -1.1949049234390259, -5.445852279663086, -3.1115128993988037, -3.2417709827423096, -2.096283435821533, -1.5649689435958862, -3.511277675628662, -2.196408271789551], [13.599597930908203, -3.586883068084717, -3.1119980812072754, -4.561516761779785, -4.122069835662842, -4.02717924118042, -2.8477108478546143, -1.8030941486358643, -4.220266342163086, -1.4385156631469727, -5.2178730964660645, -3.5644941329956055, -3.238814115524292, -2.270322799682617, -1.704636573791504, -3.74399995803833, -2.6285722255706787], [11.964216232299805, -2.686934232711792, -3.4633400440216064, -3.629030704498291, -3.3583991527557373, -3.709451675415039, -2.8092470169067383, -1.3263893127441406, -3.6701855659484863, -1.2978004217147827, -4.907573699951172, -2.941141128540039, -3.446763515472412, -2.2070932388305664, -1.6760549545288086, -3.589885711669922, -2.340965509414673]], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'tags': ['O', 'U-PER', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'L-MISC', 'O', 'O', 'O', 'O', 'O'], 'words': ['Did', 'Uriah', 'honestly', 'think', 'he', 'could', 'beat', 'The', 'Legend', 'of', 'Zelda', 'in', 'under', 'three', 'hours', '?']}\n"
     ]
    }
   ],
   "source": [
    "from allennlp.predictors.predictor import Predictor\n",
    "predictor = Predictor.from_path(\"https://s3-us-west-2.amazonaws.com/allennlp/models/ner-model-2018.12.18.tar.gz\")\n",
    "s = predictor.predict(\n",
    "  sentence=\"Did Uriah honestly think he could beat The Legend of Zelda in under three hours?\"\n",
    ")\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q_4IbVzIpQQ1"
   },
   "source": [
    "Read the train corpus (CONLL 2003 dataset (en))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 352
    },
    "colab_type": "code",
    "id": "YGzLZHQapQQ2",
    "outputId": "c92f639f-0f49-4ae3-df4f-371abebbc0c1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>through</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>London</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>protest</td>\n",
       "      <td>VB</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS    Tag\n",
       "0  Sentence: 1      Thousands  NNS      O\n",
       "1  Sentence: 1             of   IN      O\n",
       "2  Sentence: 1  demonstrators  NNS      O\n",
       "3  Sentence: 1           have  VBP      O\n",
       "4  Sentence: 1        marched  VBN      O\n",
       "5  Sentence: 1        through   IN      O\n",
       "6  Sentence: 1         London  NNP  B-geo\n",
       "7  Sentence: 1             to   TO      O\n",
       "8  Sentence: 1        protest   VB      O\n",
       "9  Sentence: 1            the   DT      O"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"gdrive/My Drive/Colab Notebooks/ner_dataset.csv\", encoding=\"latin1\")\n",
    "data = data.fillna(method=\"ffill\")\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "colab_type": "code",
    "id": "uTl5WEbFpQQ6",
    "outputId": "ec958252-dc00-4310-9ca4-6ee9a16dcf08",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: 35179\n",
      "Number of tags: 17\n"
     ]
    }
   ],
   "source": [
    "words = list(set(data[\"Word\"].values))\n",
    "words.append(\"ENDPAD\")\n",
    "print(\"Number of words: {}\".format(len(words)))\n",
    "tags = list(set(data[\"Tag\"].values))\n",
    "print(\"Number of tags: {}\".format(len(tags)))\n",
    "tag2idx = {t: i for i, t in enumerate(tags)}# indexes of tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UGNrF_dApQQ_"
   },
   "source": [
    "Class for getting sentece + tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AVmQfh9xpQRA",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                           s[\"POS\"].values.tolist(),\n",
    "                                                           s[\"Tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "2IpAO_HApQRE",
    "outputId": "d2121631-c985-4f91-e910-c078755be262"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Thousands', 'NNS', 'O'), ('of', 'IN', 'O'), ('demonstrators', 'NNS', 'O'), ('have', 'VBP', 'O'), ('marched', 'VBN', 'O'), ('through', 'IN', 'O'), ('London', 'NNP', 'B-geo'), ('to', 'TO', 'O'), ('protest', 'VB', 'O'), ('the', 'DT', 'O'), ('war', 'NN', 'O'), ('in', 'IN', 'O'), ('Iraq', 'NNP', 'B-geo'), ('and', 'CC', 'O'), ('demand', 'VB', 'O'), ('the', 'DT', 'O'), ('withdrawal', 'NN', 'O'), ('of', 'IN', 'O'), ('British', 'JJ', 'B-gpe'), ('troops', 'NNS', 'O'), ('from', 'IN', 'O'), ('that', 'DT', 'O'), ('country', 'NN', 'O'), ('.', '.', 'O')]\n",
      "Number of sentences: 47959\n",
      "Max len of sentence: 104\n"
     ]
    }
   ],
   "source": [
    "getter = SentenceGetter(data)\n",
    "sent = getter.get_next()\n",
    "print(sent)\n",
    "sentences = getter.sentences\n",
    "print(\"Number of sentences: {}\".format(len(sentences)))\n",
    "print(\"Max len of sentence: {}\".format(max([len(i) for i in sentences])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DFNNSgbVpQRM"
   },
   "source": [
    "We need to choose max_len for inputting sentence to net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KspwYF1ZpQRN"
   },
   "outputs": [],
   "source": [
    "max_len = 50\n",
    "X = [[w[0] for w in s][:max_len] for s in sentences]\n",
    "new_X = []\n",
    "for seq in X:\n",
    "    new_seq = []\n",
    "    for i in range(max_len):\n",
    "        try:\n",
    "            new_seq.append(seq[i])\n",
    "        except:\n",
    "            new_seq.append(\"__PAD__\")\n",
    "    new_X.append(new_seq)\n",
    "X = new_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RCGm2MD9pQRT"
   },
   "source": [
    "Get idx for tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aayGNB0ppQRU"
   },
   "outputs": [],
   "source": [
    "y =[torch.tensor([ tag2idx[w[2]] for w in s][0:max_len]) for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X7cF0GS4wlqd"
   },
   "outputs": [],
   "source": [
    "y = (pad_sequence(sequences=y, batch_first=False, padding_value=tag2idx[\"O\"])).t()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sYkSmye_7M6u"
   },
   "source": [
    "### Download elmo model from [allennlp](https://allennlp.org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "colab_type": "code",
    "id": "U2yHpvSGpQRY",
    "outputId": "e82d5da7-6847-4beb-e8cd-46931ad9b09c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 336/336 [00:00<00:00, 188785.82B/s]\n",
      "100%|██████████| 374434792/374434792 [00:05<00:00, 69422539.32B/s]\n"
     ]
    }
   ],
   "source": [
    "from allennlp.modules.elmo import Elmo, batch_to_ids\n",
    "\n",
    "options_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json\"\n",
    "weight_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5\"\n",
    "\n",
    "# Compute two different representation for each token.\n",
    "# Each representation is a linear weighted combination for the\n",
    "# 3 layers in ELMo (i.e., charcnn, the outputs of the two BiLSTM))\n",
    "elmo = Elmo(options_file, weight_file, 1, dropout=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EItq98QJkovj"
   },
   "outputs": [],
   "source": [
    "def embed(batch):\n",
    "  character_ids = batch_to_ids(batch)\n",
    "  return elmo(character_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 32
    },
    "colab_type": "code",
    "id": "0jsvk6oh1M7V",
    "outputId": "c68914a1-cd50-4340-a895-7107c3802a85"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 1024])"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed([['First', 'sentence', '.'],['Russia', 'is', 'big','.','putin']])['elmo_representations'][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U4rD47t0lUhn"
   },
   "source": [
    "### Now we have word embedding of size 1024 for each word and tags(y)\n",
    "Let's build a batcher +  model with bi-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GVyrUjhqlIUz"
   },
   "outputs": [],
   "source": [
    "class Batch:\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.current = 0\n",
    "    def make_batch(self, batch_size):\n",
    "        if self.current + batch_size >= len(self.X):\n",
    "            self.current = 0\n",
    "        \n",
    "        sample = embed(self.X[self.current:self.current+batch_size])['elmo_representations'][0].cuda()# batch * 50 * 1024\n",
    "        pred = self.y[self.current:self.current+batch_size].cuda()\n",
    "        self.current = self.current + batch_size\n",
    "        return sample, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-XkdNdqVhzvw"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "lr = 0.01\n",
    "hidden_size = 1024\n",
    "output_size = len(tag2idx)\n",
    "n_layers = 2\n",
    "n_batchs = 100\n",
    "print_every = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q-LCAGrCy2Qz"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(self.hidden_size, self.hidden_size, self.n_layers, dropout = 0.2)\n",
    "        self.decoder = nn.Linear(self.hidden_size, self.output_size)\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        batch_size = x.size(0)\n",
    "        out, hidden = self.lstm(x.view(1, batch_size, -1), hidden)\n",
    "        out = self.decoder(out.view(batch_size, -1))\n",
    "        return out, hidden\n",
    "      \n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(self.n_layers, batch_size, self.hidden_size, device = device).cuda(),\\\n",
    "            torch.zeros(self.n_layers, batch_size, self.hidden_size, device = device).cuda()\n",
    "    \n",
    "    def predict(x, hidden):\n",
    "        batch_size = x.size(0)\n",
    "        out, hidden = self.lstm(x.view(1, batch_size, -1), hidden)\n",
    "        out = self.decoder(out.view(batch_size, -1))\n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yRsY7K-JZf8-"
   },
   "outputs": [],
   "source": [
    "model = Net(hidden_size, input_size, n_layers).to(device=device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "loss = torch.tensor(0)\n",
    "b = Batch(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E1gAgk3GhtsO"
   },
   "outputs": [],
   "source": [
    "def timeSince(since):\n",
    "    now = time.clock()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xGFhpKyCZdK8"
   },
   "outputs": [],
   "source": [
    "def train(inp, target):\n",
    "    model.zero_grad()\n",
    "    loss = 0\n",
    "    hidden = model.init_hidden(batch_size)\n",
    "    model.train()\n",
    "    for i in range(inp.shape[1]-1):\n",
    "        output, hidden = model(inp[:,i,:], hidden)\n",
    "        loss += criterion(output.view(batch_size,-1), target[:,i])\n",
    "        \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss/ inp.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cLu1KHYLlmw2"
   },
   "outputs": [],
   "source": [
    "losses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "61_i1mPifuID"
   },
   "source": [
    "All corpus is $\\approx$ 300 bathes, I use only 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3310
    },
    "colab_type": "code",
    "id": "Z_3DI2ecZjJ3",
    "outputId": "626debfa-7295-435a-ebb7-0b81e0c25ab8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bat 1,   \tloss 2.779780864715576\n",
      "time passed 0m 34s:\n",
      "bat 2,   \tloss 1.01329505443573\n",
      "time passed 1m 10s:\n",
      "bat 3,   \tloss 0.5626169443130493\n",
      "time passed 1m 45s:\n",
      "bat 4,   \tloss 1.0504958629608154\n",
      "time passed 2m 16s:\n",
      "bat 5,   \tloss 0.39138948917388916\n",
      "time passed 2m 49s:\n",
      "bat 6,   \tloss 0.6237685084342957\n",
      "time passed 3m 21s:\n",
      "bat 7,   \tloss 0.5682610273361206\n",
      "time passed 3m 55s:\n",
      "bat 8,   \tloss 0.7098172307014465\n",
      "time passed 4m 27s:\n",
      "bat 9,   \tloss 0.6765277981758118\n",
      "time passed 4m 58s:\n",
      "bat 10,   \tloss 0.6005204916000366\n",
      "time passed 5m 31s:\n",
      "bat 11,   \tloss 0.5897429585456848\n",
      "time passed 6m 4s:\n",
      "bat 12,   \tloss 0.44916483759880066\n",
      "time passed 6m 37s:\n",
      "bat 13,   \tloss 0.4250081181526184\n",
      "time passed 7m 9s:\n",
      "bat 14,   \tloss 0.45406150817871094\n",
      "time passed 7m 41s:\n",
      "bat 15,   \tloss 0.425199419260025\n",
      "time passed 8m 14s:\n",
      "bat 16,   \tloss 0.3851526975631714\n",
      "time passed 8m 47s:\n",
      "bat 17,   \tloss 0.4360050559043884\n",
      "time passed 9m 21s:\n",
      "bat 18,   \tloss 0.4006953835487366\n",
      "time passed 9m 52s:\n",
      "bat 19,   \tloss 0.3833058178424835\n",
      "time passed 10m 25s:\n",
      "bat 20,   \tloss 0.36324262619018555\n",
      "time passed 10m 57s:\n",
      "bat 21,   \tloss 0.4116072356700897\n",
      "time passed 11m 29s:\n",
      "bat 22,   \tloss 0.4108138680458069\n",
      "time passed 12m 3s:\n",
      "bat 23,   \tloss 0.4293060302734375\n",
      "time passed 12m 35s:\n",
      "bat 24,   \tloss 0.3516250550746918\n",
      "time passed 13m 7s:\n",
      "bat 25,   \tloss 0.32486534118652344\n",
      "time passed 13m 39s:\n",
      "bat 26,   \tloss 0.3373158872127533\n",
      "time passed 14m 12s:\n",
      "bat 27,   \tloss 0.3442690968513489\n",
      "time passed 14m 46s:\n",
      "bat 28,   \tloss 0.30984532833099365\n",
      "time passed 15m 17s:\n",
      "bat 29,   \tloss 0.3508414030075073\n",
      "time passed 15m 49s:\n",
      "bat 30,   \tloss 0.311451256275177\n",
      "time passed 16m 21s:\n",
      "bat 31,   \tloss 0.2223328799009323\n",
      "time passed 16m 53s:\n",
      "bat 32,   \tloss 0.2605147063732147\n",
      "time passed 17m 27s:\n",
      "bat 33,   \tloss 0.225677028298378\n",
      "time passed 17m 58s:\n",
      "bat 34,   \tloss 0.2257808893918991\n",
      "time passed 18m 29s:\n",
      "bat 35,   \tloss 0.25904348492622375\n",
      "time passed 19m 3s:\n",
      "bat 36,   \tloss 0.21068398654460907\n",
      "time passed 19m 34s:\n",
      "bat 37,   \tloss 0.20768874883651733\n",
      "time passed 20m 7s:\n",
      "bat 38,   \tloss 0.20743942260742188\n",
      "time passed 20m 38s:\n",
      "bat 39,   \tloss 0.1752631664276123\n",
      "time passed 21m 10s:\n",
      "bat 40,   \tloss 0.20266583561897278\n",
      "time passed 21m 42s:\n",
      "bat 41,   \tloss 0.19222868978977203\n",
      "time passed 22m 14s:\n",
      "bat 42,   \tloss 0.2072589248418808\n",
      "time passed 22m 48s:\n",
      "bat 43,   \tloss 0.17513366043567657\n",
      "time passed 23m 20s:\n",
      "bat 44,   \tloss 0.16872058808803558\n",
      "time passed 23m 51s:\n",
      "bat 45,   \tloss 0.16595254838466644\n",
      "time passed 24m 25s:\n",
      "bat 46,   \tloss 0.1755552440881729\n",
      "time passed 24m 56s:\n",
      "bat 47,   \tloss 0.1729183793067932\n",
      "time passed 25m 29s:\n",
      "bat 48,   \tloss 0.1703444868326187\n",
      "time passed 26m 1s:\n",
      "bat 49,   \tloss 0.19923025369644165\n",
      "time passed 26m 33s:\n",
      "bat 50,   \tloss 0.1435762494802475\n",
      "time passed 27m 5s:\n",
      "bat 51,   \tloss 0.16036511957645416\n",
      "time passed 27m 37s:\n",
      "bat 52,   \tloss 0.1792144477367401\n",
      "time passed 28m 10s:\n",
      "bat 53,   \tloss 0.1548994481563568\n",
      "time passed 28m 41s:\n",
      "bat 54,   \tloss 0.1657533347606659\n",
      "time passed 29m 13s:\n",
      "bat 55,   \tloss 0.14749668538570404\n",
      "time passed 29m 46s:\n",
      "bat 56,   \tloss 0.13123001158237457\n",
      "time passed 30m 17s:\n",
      "bat 57,   \tloss 0.15630388259887695\n",
      "time passed 30m 50s:\n",
      "bat 58,   \tloss 0.1472146064043045\n",
      "time passed 31m 21s:\n",
      "bat 59,   \tloss 0.16231407225131989\n",
      "time passed 31m 52s:\n",
      "bat 60,   \tloss 0.1526951789855957\n",
      "time passed 32m 25s:\n",
      "bat 61,   \tloss 0.14423030614852905\n",
      "time passed 32m 57s:\n",
      "bat 62,   \tloss 0.14996442198753357\n",
      "time passed 33m 30s:\n",
      "bat 63,   \tloss 0.15333986282348633\n",
      "time passed 34m 1s:\n",
      "bat 64,   \tloss 0.14768388867378235\n",
      "time passed 34m 35s:\n",
      "bat 65,   \tloss 0.14797648787498474\n",
      "time passed 35m 7s:\n",
      "bat 66,   \tloss 0.14442241191864014\n",
      "time passed 35m 38s:\n",
      "bat 67,   \tloss 0.1453269124031067\n",
      "time passed 36m 12s:\n",
      "bat 68,   \tloss 0.16012164950370789\n",
      "time passed 36m 43s:\n",
      "bat 69,   \tloss 0.14791971445083618\n",
      "time passed 37m 15s:\n",
      "bat 70,   \tloss 0.13018813729286194\n",
      "time passed 37m 49s:\n",
      "bat 71,   \tloss 0.15383653342723846\n",
      "time passed 38m 20s:\n",
      "bat 72,   \tloss 0.11715230345726013\n",
      "time passed 38m 53s:\n",
      "bat 73,   \tloss 0.1284419745206833\n",
      "time passed 39m 24s:\n",
      "bat 74,   \tloss 0.14124414324760437\n",
      "time passed 39m 58s:\n",
      "bat 75,   \tloss 0.1524251103401184\n",
      "time passed 40m 30s:\n",
      "bat 76,   \tloss 0.12301427870988846\n",
      "time passed 41m 1s:\n",
      "bat 77,   \tloss 0.1388445496559143\n",
      "time passed 41m 35s:\n",
      "bat 78,   \tloss 0.13614147901535034\n",
      "time passed 42m 6s:\n",
      "bat 79,   \tloss 0.12200669944286346\n",
      "time passed 42m 38s:\n",
      "bat 80,   \tloss 0.14041638374328613\n",
      "time passed 43m 11s:\n",
      "bat 81,   \tloss 0.142555370926857\n",
      "time passed 43m 42s:\n",
      "bat 82,   \tloss 0.1060313880443573\n",
      "time passed 44m 15s:\n",
      "bat 83,   \tloss 0.11126381903886795\n",
      "time passed 44m 47s:\n",
      "bat 84,   \tloss 0.1266920566558838\n",
      "time passed 45m 20s:\n",
      "bat 85,   \tloss 0.1201038584113121\n",
      "time passed 45m 52s:\n",
      "bat 86,   \tloss 0.12424881011247635\n",
      "time passed 46m 23s:\n",
      "bat 87,   \tloss 0.10317026823759079\n",
      "time passed 46m 57s:\n",
      "bat 88,   \tloss 0.09583153575658798\n",
      "time passed 47m 28s:\n",
      "bat 89,   \tloss 0.11196418851613998\n",
      "time passed 48m 0s:\n",
      "bat 90,   \tloss 0.12585236132144928\n",
      "time passed 48m 33s:\n",
      "bat 91,   \tloss 0.09976138919591904\n",
      "time passed 49m 4s:\n",
      "bat 92,   \tloss 0.1343989223241806\n",
      "time passed 49m 37s:\n",
      "bat 93,   \tloss 0.10793568193912506\n",
      "time passed 50m 10s:\n",
      "bat 94,   \tloss 0.08179739117622375\n",
      "time passed 50m 41s:\n",
      "bat 95,   \tloss 0.12234430015087128\n",
      "time passed 51m 14s:\n",
      "bat 96,   \tloss 0.10605595260858536\n",
      "time passed 51m 46s:\n",
      "bat 97,   \tloss 0.1014084443449974\n",
      "time passed 52m 19s:\n",
      "bat 98,   \tloss 0.1168830469250679\n",
      "time passed 52m 52s:\n",
      "bat 99,   \tloss 0.10036435723304749\n",
      "time passed 53m 23s:\n",
      "bat 100,   \tloss 0.09640730917453766\n",
      "time passed 53m 56s:\n"
     ]
    }
   ],
   "source": [
    "start_time = time.clock()\n",
    "for bat in range(1, n_batchs + 1):\n",
    "    loss = train(*b.make_batch(batch_size))\n",
    "    losses.append(loss)\n",
    "    if bat % print_every == 0:\n",
    "        print('bat {},   \\tloss {}'.format(bat, losses[-1]))\n",
    "        print('time passed %s:' %(timeSince(start_time)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "SFDLhue9Wewc",
    "outputId": "d816c5b9-91b2-4ff6-a2f3-bf12a1fb876f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Net. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(model, 'gdrive/My Drive/Colab Notebooks/tr_learn_34.dms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cl58N90IWqhD"
   },
   "outputs": [],
   "source": [
    "torch.save(optimizer, 'gdrive/My Drive/Colab Notebooks/adam_tr_learn_34')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "colab_type": "code",
    "id": "5wgH2n7qtcCO",
    "outputId": "c150f32f-9141-4a5d-981e-3db6c8e4c4c8"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuIAAAG7CAYAAACGivCdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7Eu+MAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "plt.plot(range(len(losses)), losses)\n",
    "plt.xlabel(\"$batch$\", fontsize=25)\n",
    "plt.ylabel(\"$loss$\", fontsize=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vxe2T_lUi1e_"
   },
   "source": [
    "## Check accuracy + f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1UuCClK3PN8B"
   },
   "outputs": [],
   "source": [
    "def predict(batch_size):\n",
    "    hidden = model.init_hidden(batch_size)\n",
    "    inp, target = b.make_batch(batch_size)\n",
    "    hidden = model.init_hidden(batch_size)\n",
    "    pred = []\n",
    "    for i in range(inp.shape[1]):\n",
    "      output, hidden = model(j[:,i,:], hidden)\n",
    "      _, index = torch.max(func.softmax(output, dim = 1),1)\n",
    "      pred.append(index.item())\n",
    "    return accuracy_score(target[0].cpu().detach().numpy(),pred), f1_score(target[0].cpu().detach().numpy(),pred, average='macro')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 169
    },
    "colab_type": "code",
    "id": "AodsseNIawZo",
    "outputId": "6f24335b-97a7-46d5-fd2a-91b0756da564"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY:\t 0.9339999999999999\n",
      "F1- SCORE:\t 0.2471519373509746\n"
     ]
    }
   ],
   "source": [
    "print('ACCURACY:\\t {}'.format(np.mean([predict(1)[0] for i in range(10)])))\n",
    "print('F1- SCORE:\\t {}'.format(np.mean([predict(1)[1] for i in range(10)])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9eh17u9qedbL"
   },
   "source": [
    "Accuracy is great, in case I taught model more, f1 would be around 0.8"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "task4.1_transfer_learning.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
